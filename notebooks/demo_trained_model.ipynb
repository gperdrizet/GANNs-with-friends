{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e035cef",
   "metadata": {},
   "source": [
    "# Distributed GAN Training Demo - Model Visualization\n",
    "\n",
    "This notebook demonstrates the results from our distributed GAN training system. You can use it to visualize:\n",
    "- Training loss curves (Generator and Discriminator)\n",
    "- Generated face samples\n",
    "- Training progression over epochs\n",
    "- Model architecture details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b00a7f3a",
   "metadata": {},
   "source": [
    "# DCGAN Trained Model Demo\n",
    "\n",
    "This notebook demonstrates the trained DCGAN model for generating celebrity faces.\n",
    "\n",
    "**Contents:**\n",
    "1. Load trained model checkpoint\n",
    "2. Visualize training history (learning curves)\n",
    "3. Generate new face images\n",
    "4. Show training progression\n",
    "\n",
    "**Requirements:**\n",
    "- Trained model checkpoint in `../outputs_local/checkpoints/` or `../outputs/checkpoints/`\n",
    "- PyTorch and required dependencies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b440e86a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "# Add src to path to import our modules\n",
    "sys.path.insert(0, '../src')\n",
    "\n",
    "from models.dcgan import Generator, Discriminator\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('default')\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"PyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f144d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "LATENT_DIM = 100\n",
    "IMAGE_SIZE = 64\n",
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Checkpoint paths (try both local and distributed outputs)\n",
    "CHECKPOINT_PATHS = [\n",
    "    '../outputs_local/checkpoints/checkpoint_latest.pth',\n",
    "    '../outputs/checkpoints/checkpoint_latest.pth',\n",
    "]\n",
    "\n",
    "# Find available checkpoint\n",
    "CHECKPOINT_PATH = None\n",
    "for path in CHECKPOINT_PATHS:\n",
    "    if Path(path).exists():\n",
    "        CHECKPOINT_PATH = path\n",
    "        print(f\"Found checkpoint: {path}\")\n",
    "        break\n",
    "\n",
    "if CHECKPOINT_PATH is None:\n",
    "    print(\"WARNING: No checkpoint found! Please train a model first.\")\n",
    "    print(\"Expected locations:\")\n",
    "    for path in CHECKPOINT_PATHS:\n",
    "        print(f\"  - {path}\")\n",
    "else:\n",
    "    print(f\"\\nUsing checkpoint: {CHECKPOINT_PATH}\")\n",
    "    print(f\"Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27756ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CHECKPOINT_PATH:\n",
    "    # Initialize models\n",
    "    generator = Generator(latent_dim=LATENT_DIM).to(DEVICE)\n",
    "    discriminator = Discriminator().to(DEVICE)\n",
    "    \n",
    "    # Load checkpoint\n",
    "    print(\"Loading checkpoint...\")\n",
    "    checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "    \n",
    "    # Load model weights\n",
    "    generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "    discriminator.load_state_dict(checkpoint['discriminator_state_dict'])\n",
    "    \n",
    "    # Set to evaluation mode\n",
    "    generator.eval()\n",
    "    discriminator.eval()\n",
    "    \n",
    "    # Extract training information\n",
    "    epoch = checkpoint.get('epoch', 'Unknown')\n",
    "    g_losses = checkpoint.get('g_losses', [])\n",
    "    d_losses = checkpoint.get('d_losses', [])\n",
    "    \n",
    "    print(f\"âœ“ Loaded checkpoint from epoch {epoch}\")\n",
    "    print(f\"âœ“ Generator parameters: {sum(p.numel() for p in generator.parameters()):,}\")\n",
    "    print(f\"âœ“ Discriminator parameters: {sum(p.numel() for p in discriminator.parameters()):,}\")\n",
    "    \n",
    "    if g_losses:\n",
    "        print(f\"âœ“ Training history: {len(g_losses)} epochs\")\n",
    "        print(f\"  Final G loss: {g_losses[-1]:.4f}\")\n",
    "        print(f\"  Final D loss: {d_losses[-1]:.4f}\")\n",
    "else:\n",
    "    print(\"Warning: Skipping model loading - no checkpoint available\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f615bb71",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CHECKPOINT_PATH and g_losses:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Plot losses\n",
    "    epochs = range(1, len(g_losses) + 1)\n",
    "    \n",
    "    # Generator and Discriminator losses\n",
    "    axes[0].plot(epochs, g_losses, label='Generator Loss', color='blue', linewidth=2)\n",
    "    axes[0].plot(epochs, d_losses, label='Discriminator Loss', color='red', linewidth=2)\n",
    "    axes[0].set_xlabel('Epoch', fontsize=12)\n",
    "    axes[0].set_ylabel('Loss', fontsize=12)\n",
    "    axes[0].set_title('Training Losses Over Time', fontsize=14, fontweight='bold')\n",
    "    axes[0].legend(fontsize=11)\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Smoothed losses (moving average)\n",
    "    window = min(5, len(g_losses) // 10) if len(g_losses) > 10 else 1\n",
    "    if window > 1:\n",
    "        g_losses_smooth = np.convolve(g_losses, np.ones(window)/window, mode='valid')\n",
    "        d_losses_smooth = np.convolve(d_losses, np.ones(window)/window, mode='valid')\n",
    "        epochs_smooth = range(window, len(g_losses) + 1)\n",
    "        \n",
    "        axes[1].plot(epochs_smooth, g_losses_smooth, label='Generator (smoothed)', \n",
    "                    color='blue', linewidth=2)\n",
    "        axes[1].plot(epochs_smooth, d_losses_smooth, label='Discriminator (smoothed)', \n",
    "                    color='red', linewidth=2)\n",
    "        axes[1].set_xlabel('Epoch', fontsize=12)\n",
    "        axes[1].set_ylabel('Loss', fontsize=12)\n",
    "        axes[1].set_title(f'Smoothed Losses (window={window})', fontsize=14, fontweight='bold')\n",
    "        axes[1].legend(fontsize=11)\n",
    "        axes[1].grid(True, alpha=0.3)\n",
    "    else:\n",
    "        axes[1].axis('off')\n",
    "        axes[1].text(0.5, 0.5, 'Not enough epochs\\nfor smoothing', \n",
    "                    ha='center', va='center', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Training completed after {len(g_losses)} epochs\")\n",
    "    print(f\"Final Generator Loss: {g_losses[-1]:.4f}\")\n",
    "    print(f\"Final Discriminator Loss: {d_losses[-1]:.4f}\")\n",
    "else:\n",
    "    print(\"Warning: No training history available in checkpoint\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a3934a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CHECKPOINT_PATH:\n",
    "    # Generate images\n",
    "    num_samples = 64  # 8x8 grid\n",
    "    \n",
    "    print(f\"Generating {num_samples} new face images...\")\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Sample random noise\n",
    "        noise = torch.randn(num_samples, LATENT_DIM, 1, 1, device=DEVICE)\n",
    "        \n",
    "        # Generate images\n",
    "        generated_images = generator(noise)\n",
    "        \n",
    "        # Move to CPU and convert to numpy\n",
    "        generated_images = generated_images.cpu()\n",
    "    \n",
    "    print(f\"âœ“ Generated {num_samples} images\")\n",
    "    print(f\"  Image shape: {generated_images.shape}\")\n",
    "    print(f\"  Value range: [{generated_images.min():.2f}, {generated_images.max():.2f}]\")\n",
    "else:\n",
    "    print(\"Warning: Skipping generation - no model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48fa91dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CHECKPOINT_PATH:\n",
    "    # Create a grid of images\n",
    "    nrow = 8\n",
    "    ncol = 8\n",
    "    \n",
    "    fig, axes = plt.subplots(nrow, ncol, figsize=(16, 16))\n",
    "    \n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        if i < len(generated_images):\n",
    "            # Convert from [-1, 1] to [0, 1]\n",
    "            img = (generated_images[i].permute(1, 2, 0).numpy() + 1) / 2\n",
    "            img = np.clip(img, 0, 1)\n",
    "            \n",
    "            ax.imshow(img)\n",
    "            ax.axis('off')\n",
    "        else:\n",
    "            ax.axis('off')\n",
    "    \n",
    "    plt.suptitle('Generated Celebrity Faces', fontsize=18, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Displayed {min(num_samples, nrow*ncol)} generated faces in {nrow}x{ncol} grid\")\n",
    "else:\n",
    "    print(\"Warning: No images to display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1951e02f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look for saved sample images\n",
    "sample_dirs = [\n",
    "    '../outputs_local/samples/',\n",
    "    '../outputs/samples/',\n",
    "]\n",
    "\n",
    "sample_images = []\n",
    "for sample_dir in sample_dirs:\n",
    "    sample_path = Path(sample_dir)\n",
    "    if sample_path.exists():\n",
    "        # Get all image files sorted by name\n",
    "        images = sorted(sample_path.glob('*.png'))\n",
    "        if images:\n",
    "            print(f\"Found {len(images)} sample images in {sample_dir}\")\n",
    "            \n",
    "            # Select evenly spaced samples to show progression\n",
    "            num_to_show = min(8, len(images))\n",
    "            indices = np.linspace(0, len(images)-1, num_to_show, dtype=int)\n",
    "            \n",
    "            for idx in indices:\n",
    "                img_path = images[idx]\n",
    "                img = Image.open(img_path)\n",
    "                sample_images.append((img_path.name, img))\n",
    "            \n",
    "            print(f\"Selected {len(sample_images)} images to show progression\")\n",
    "            break\n",
    "\n",
    "if not sample_images:\n",
    "    print(\"No saved sample images found. Sample images are saved during training in:\")\n",
    "    for sample_dir in sample_dirs:\n",
    "        print(f\"  - {sample_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fe48aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "if sample_images:\n",
    "    num_images = len(sample_images)\n",
    "    ncols = min(4, num_images)\n",
    "    nrows = (num_images + ncols - 1) // ncols\n",
    "    \n",
    "    fig, axes = plt.subplots(nrows, ncols, figsize=(ncols * 4, nrows * 4))\n",
    "    \n",
    "    if num_images == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flat if num_images > ncols else axes\n",
    "    \n",
    "    for idx, (name, img) in enumerate(sample_images):\n",
    "        if idx < len(axes):\n",
    "            axes[idx].imshow(img)\n",
    "            axes[idx].set_title(name.replace('.png', '').replace('_', ' '), fontsize=10)\n",
    "            axes[idx].axis('off')\n",
    "    \n",
    "    # Hide unused subplots\n",
    "    for idx in range(len(sample_images), len(axes)):\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.suptitle('Training Progression - Generated Samples Over Time', \n",
    "                 fontsize=16, fontweight='bold', y=0.995)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Displayed {num_images} samples showing training progression\")\n",
    "    print(f\"\\nObservations:\")\n",
    "    print(\"  - Early epochs: Random noise and blurry patterns\")\n",
    "    print(\"  - Middle epochs: Face-like structures emerge\")\n",
    "    print(\"  - Later epochs: Detailed, realistic faces\")\n",
    "else:\n",
    "    print(\"No progression images to display\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a2bb2d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_faces(num_faces=16, seed=None):\n",
    "    \"\"\"\n",
    "    Generate new faces using the trained generator.\n",
    "    \n",
    "    Args:\n",
    "        num_faces: Number of faces to generate\n",
    "        seed: Random seed for reproducibility (optional)\n",
    "    \"\"\"\n",
    "    if not CHECKPOINT_PATH:\n",
    "        print(\"Warning: No model loaded\")\n",
    "        return\n",
    "    \n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        noise = torch.randn(num_faces, LATENT_DIM, 1, 1, device=DEVICE)\n",
    "        images = generator(noise).cpu()\n",
    "    \n",
    "    # Display images\n",
    "    nrow = int(np.ceil(np.sqrt(num_faces)))\n",
    "    ncol = nrow\n",
    "    \n",
    "    fig, axes = plt.subplots(nrow, ncol, figsize=(ncol * 2, nrow * 2))\n",
    "    \n",
    "    if num_faces == 1:\n",
    "        axes = [axes]\n",
    "    else:\n",
    "        axes = axes.flat\n",
    "    \n",
    "    for i, ax in enumerate(axes):\n",
    "        if i < num_faces:\n",
    "            img = (images[i].permute(1, 2, 0).numpy() + 1) / 2\n",
    "            img = np.clip(img, 0, 1)\n",
    "            ax.imshow(img)\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.suptitle(f'{num_faces} Newly Generated Faces', fontsize=14, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Example: Generate 16 new faces\n",
    "if CHECKPOINT_PATH:\n",
    "    print(\"Generating 16 new faces...\")\n",
    "    generate_faces(16, seed=42)\n",
    "    \n",
    "    print(\"\\nðŸ’¡ Tip: Call generate_faces(N) to generate N faces\")\n",
    "    print(\"   Example: generate_faces(25, seed=123)\")\n",
    "else:\n",
    "    print(\"Warning: Skipping - no model loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "514c5820",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CHECKPOINT_PATH:\n",
    "    print(\"=\"*70)\n",
    "    print(\"DCGAN MODEL SUMMARY\")\n",
    "    print(\"=\"*70)\n",
    "    print(f\"\\n Training Information:\")\n",
    "    print(f\"   â€¢ Training completed: {epoch} epochs\")\n",
    "    print(f\"   â€¢ Final Generator Loss: {g_losses[-1]:.4f}\" if g_losses else \"   â€¢ No loss history\")\n",
    "    print(f\"   â€¢ Final Discriminator Loss: {d_losses[-1]:.4f}\" if d_losses else \"\")\n",
    "    \n",
    "    print(f\"\\n Model Architecture:\")\n",
    "    print(f\"   â€¢ Generator Parameters: {sum(p.numel() for p in generator.parameters()):,}\")\n",
    "    print(f\"   â€¢ Discriminator Parameters: {sum(p.numel() for p in discriminator.parameters()):,}\")\n",
    "    print(f\"   â€¢ Latent Dimension: {LATENT_DIM}\")\n",
    "    print(f\"   â€¢ Image Size: {IMAGE_SIZE}x{IMAGE_SIZE}\")\n",
    "    \n",
    "    print(f\"\\n Hardware:\")\n",
    "    print(f\"   â€¢ Device: {DEVICE}\")\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"   â€¢ GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    \n",
    "    print(f\"\\n Key Insights:\")\n",
    "    if g_losses and d_losses:\n",
    "        print(f\"   â€¢ Training stability: {'Good' if abs(g_losses[-1] - d_losses[-1]) < 1.0 else 'Needs tuning'}\")\n",
    "        print(f\"   â€¢ Loss convergence: {'Converged' if len(g_losses) > 10 and abs(g_losses[-1] - g_losses[-5]) < 0.1 else 'Still improving'}\")\n",
    "    \n",
    "    print(f\"\\n What This Model Does:\")\n",
    "    print(f\"   â€¢ Generates realistic celebrity faces from random noise\")\n",
    "    print(f\"   â€¢ Learned from CelebA dataset (celebrity images)\")\n",
    "    print(f\"   â€¢ Can create infinite unique faces\")\n",
    "    print(f\"   â€¢ No two generated faces are exactly the same\")\n",
    "    \n",
    "    print(f\"\\n Next Steps:\")\n",
    "    print(f\"   â€¢ Try generating more images with different seeds\")\n",
    "    print(f\"   â€¢ Experiment with latent space interpolation\")\n",
    "    print(f\"   â€¢ Train for more epochs to improve quality\")\n",
    "    print(f\"   â€¢ Try other GAN architectures (StyleGAN, ProGAN)\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "else:\n",
    "    print(\"Warning: No model loaded - train a model first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3490d779",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "##  Conclusion\n",
    "\n",
    "This notebook demonstrated a trained DCGAN model that can generate realistic celebrity faces. The model learned to map random noise vectors to face images through adversarial training.\n",
    "\n",
    "**Key Takeaways:**\n",
    "- GANs learn to generate realistic images without explicit pixel-level supervision\n",
    "- The generator creates faces from random latent vectors\n",
    "- Training involves a minimax game between generator and discriminator\n",
    "- Quality improves with more training epochs and larger datasets\n",
    "\n",
    "**Further Experimentation:**\n",
    "- Try different random seeds to generate diverse faces\n",
    "- Explore latent space interpolation (morphing between faces)\n",
    "- Fine-tune on specific face attributes\n",
    "- Experiment with conditional GANs (control age, gender, etc.)\n",
    "\n",
    "**Resources:**\n",
    "- [DCGAN Paper](https://arxiv.org/abs/1511.06434)\n",
    "- [CelebA Dataset](http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html)\n",
    "- [Project Repository](https://github.com/YOUR_USERNAME/GANNs-with-freinds)\n",
    "\n",
    "---\n",
    "\n",
    "**Created as part of the Distributed GAN Training Project** "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "308ad3ad",
   "metadata": {},
   "source": [
    "## 9. Summary and Model Insights\n",
    "\n",
    "Key observations and insights from the trained DCGAN model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7a60aa",
   "metadata": {},
   "source": [
    "## 8. Interactive Generation (Optional)\n",
    "\n",
    "Generate specific numbers of new images on demand."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07435145",
   "metadata": {},
   "source": [
    "### Display Training Progression\n",
    "\n",
    "Show how the generated images improved over the course of training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0097e16f",
   "metadata": {},
   "source": [
    "## 7. Training Progression (Optional)\n",
    "\n",
    "If you have saved sample images during training, we can visualize how the generator improved over time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6092d9",
   "metadata": {},
   "source": [
    "## 6. Display Generated Images\n",
    "\n",
    "Visualize the generated face images in a grid layout."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "992052fe",
   "metadata": {},
   "source": [
    "## 5. Generate New Face Images\n",
    "\n",
    "Generate new celebrity face images using the trained generator with random noise inputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f14695",
   "metadata": {},
   "source": [
    "## 4. Visualize Training History - Learning Curves\n",
    "\n",
    "Plot the generator and discriminator losses over training epochs to understand model convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fee825d",
   "metadata": {},
   "source": [
    "## 3. Load Trained Model\n",
    "\n",
    "Load the generator and discriminator from the saved checkpoint."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf85098",
   "metadata": {},
   "source": [
    "## 2. Configuration and Setup\n",
    "\n",
    "Set up paths and parameters for loading the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7276fb19",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries\n",
    "\n",
    "Import necessary libraries for loading models, plotting, and image visualization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be8706e",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73dfb1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Add src to path\n",
    "sys.path.insert(0, str(Path(__file__).parent.parent / 'src') if '__file__' in globals() else '../src')\n",
    "\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import json\n",
    "\n",
    "from models.dcgan import Generator, Discriminator\n",
    "\n",
    "# Set up matplotlib\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26db55a7",
   "metadata": {},
   "source": [
    "## Configuration\n",
    "\n",
    "Set the paths to your trained model checkpoint and output directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f8a9695",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "CHECKPOINT_PATH = '../outputs_local/checkpoint_latest.pth'  # or '../outputs/checkpoint_latest.pth' for distributed\n",
    "OUTPUT_DIR = Path('../outputs_local')  # or Path('../outputs') for distributed\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f\"Using device: {DEVICE}\")\n",
    "print(f\"Checkpoint: {CHECKPOINT_PATH}\")\n",
    "print(f\"Output directory: {OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ae4c0b",
   "metadata": {},
   "source": [
    "## Load Trained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1573944e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load checkpoint\n",
    "checkpoint = torch.load(CHECKPOINT_PATH, map_location=DEVICE)\n",
    "\n",
    "# Extract configuration from checkpoint\n",
    "latent_dim = checkpoint.get('latent_dim', 100)\n",
    "image_size = checkpoint.get('image_size', 64)\n",
    "\n",
    "# Initialize models\n",
    "generator = Generator(latent_dim=latent_dim).to(DEVICE)\n",
    "discriminator = Discriminator().to(DEVICE)\n",
    "\n",
    "# Load weights\n",
    "generator.load_state_dict(checkpoint['generator_state_dict'])\n",
    "discriminator.load_state_dict(checkpoint['discriminator_state_dict'])\n",
    "\n",
    "# Set to evaluation mode\n",
    "generator.eval()\n",
    "discriminator.eval()\n",
    "\n",
    "print(f\"Loaded checkpoint from epoch {checkpoint['epoch']}\")\n",
    "print(f\"Iteration: {checkpoint['iteration']}\")\n",
    "print(f\"Generator loss: {checkpoint.get('g_loss', 'N/A'):.4f}\")\n",
    "print(f\"Discriminator loss: {checkpoint.get('d_loss', 'N/A'):.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50ae62f1",
   "metadata": {},
   "source": [
    "## Training Learning Curves\n",
    "\n",
    "Visualize how the Generator and Discriminator losses evolved during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bcbfa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training history if available\n",
    "history_file = OUTPUT_DIR / 'training_history.json'\n",
    "\n",
    "if history_file.exists():\n",
    "    with open(history_file, 'r') as f:\n",
    "        history = json.load(f)\n",
    "    \n",
    "    iterations = history['iterations']\n",
    "    g_losses = history['g_losses']\n",
    "    d_losses = history['d_losses']\n",
    "    \n",
    "    # Plot losses\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Generator loss\n",
    "    ax1.plot(iterations, g_losses, label='Generator Loss', color='blue', alpha=0.7)\n",
    "    ax1.set_xlabel('Iteration')\n",
    "    ax1.set_ylabel('Loss')\n",
    "    ax1.set_title('Generator Loss Over Time')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Discriminator loss\n",
    "    ax2.plot(iterations, d_losses, label='Discriminator Loss', color='red', alpha=0.7)\n",
    "    ax2.set_xlabel('Iteration')\n",
    "    ax2.set_ylabel('Loss')\n",
    "    ax2.set_title('Discriminator Loss Over Time')\n",
    "    ax2.legend()\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # Combined plot\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(iterations, g_losses, label='Generator Loss', color='blue', alpha=0.7)\n",
    "    plt.plot(iterations, d_losses, label='Discriminator Loss', color='red', alpha=0.7)\n",
    "    plt.xlabel('Iteration')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Training Loss Curves')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Total iterations: {len(iterations)}\")\n",
    "    print(f\"Final G loss: {g_losses[-1]:.4f}\")\n",
    "    print(f\"Final D loss: {d_losses[-1]:.4f}\")\n",
    "else:\n",
    "    print(f\"Training history not found at {history_file}\")\n",
    "    print(\"Skipping loss visualization\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a450f1",
   "metadata": {},
   "source": [
    "## Generate New Face Images\n",
    "\n",
    "Generate a batch of fresh face images using the trained generator."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80f1bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate images\n",
    "num_samples = 64\n",
    "z = torch.randn(num_samples, latent_dim, 1, 1, device=DEVICE)\n",
    "\n",
    "with torch.no_grad():\n",
    "    fake_images = generator(z)\n",
    "\n",
    "# Convert to numpy for visualization\n",
    "fake_images = fake_images.cpu()\n",
    "fake_images = (fake_images + 1) / 2  # Denormalize from [-1, 1] to [0, 1]\n",
    "fake_images = fake_images.permute(0, 2, 3, 1).numpy()\n",
    "\n",
    "print(f\"Generated {num_samples} images of shape {fake_images.shape[1:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0793dc",
   "metadata": {},
   "source": [
    "## Display Generated Faces Grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80932115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display grid of generated faces\n",
    "grid_size = 8\n",
    "fig, axes = plt.subplots(grid_size, grid_size, figsize=(16, 16))\n",
    "\n",
    "for i in range(grid_size):\n",
    "    for j in range(grid_size):\n",
    "        idx = i * grid_size + j\n",
    "        axes[i, j].imshow(fake_images[idx])\n",
    "        axes[i, j].axis('off')\n",
    "\n",
    "plt.suptitle('Generated Faces from Trained GAN', fontsize=16, y=0.995)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926f433f",
   "metadata": {},
   "source": [
    "## Training Progression\n",
    "\n",
    "View how the generated images improved over the course of training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e7f945",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find sample images saved during training\n",
    "sample_files = sorted(OUTPUT_DIR.glob('samples_iter_*.png'))\n",
    "\n",
    "if sample_files:\n",
    "    # Show progression: first, middle, and latest samples\n",
    "    num_checkpoints = min(6, len(sample_files))\n",
    "    indices = np.linspace(0, len(sample_files) - 1, num_checkpoints, dtype=int)\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i, idx in enumerate(indices):\n",
    "        if i < num_checkpoints:\n",
    "            img = Image.open(sample_files[idx])\n",
    "            axes[i].imshow(img)\n",
    "            axes[i].set_title(f'Iteration {sample_files[idx].stem.split(\"_\")[-1]}')\n",
    "            axes[i].axis('off')\n",
    "    \n",
    "    plt.suptitle('Training Progression', fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Found {len(sample_files)} sample checkpoints\")\n",
    "else:\n",
    "    print(\"No sample images found in output directory\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e08764ae",
   "metadata": {},
   "source": [
    "## Interactive Generation\n",
    "\n",
    "Generate new batches of faces on demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b26feff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_faces(n=16, seed=None):\n",
    "    \"\"\"Generate n face images.\"\"\"\n",
    "    if seed is not None:\n",
    "        torch.manual_seed(seed)\n",
    "    \n",
    "    z = torch.randn(n, latent_dim, 1, 1, device=DEVICE)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        images = generator(z)\n",
    "    \n",
    "    images = images.cpu()\n",
    "    images = (images + 1) / 2  # Denormalize\n",
    "    images = images.permute(0, 2, 3, 1).numpy()\n",
    "    \n",
    "    # Display\n",
    "    grid_size = int(np.ceil(np.sqrt(n)))\n",
    "    fig, axes = plt.subplots(grid_size, grid_size, figsize=(12, 12))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for i in range(grid_size * grid_size):\n",
    "        if i < n:\n",
    "            axes[i].imshow(images[i])\n",
    "        axes[i].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Try it out!\n",
    "print(\"Generating 16 random faces...\")\n",
    "generate_faces(16, seed=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08821f0d",
   "metadata": {},
   "source": [
    "## Model Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcefc6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model parameter counts\n",
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "g_params = count_parameters(generator)\n",
    "d_params = count_parameters(discriminator)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"MODEL SUMMARY\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Generator parameters:     {g_params:,}\")\n",
    "print(f\"Discriminator parameters: {d_params:,}\")\n",
    "print(f\"Total parameters:         {g_params + d_params:,}\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"\\nLatent dimension: {latent_dim}\")\n",
    "print(f\"Image size: {image_size}x{image_size}\")\n",
    "print(f\"Training device: {DEVICE}\")\n",
    "print(f\"Epochs trained: {checkpoint['epoch']}\")\n",
    "print(f\"Total iterations: {checkpoint['iteration']}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b078037",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated:\n",
    "- - Loading a trained DCGAN checkpoint\n",
    "- - Visualizing training loss curves\n",
    "- - Generating new face images\n",
    "- - Viewing training progression\n",
    "- - Interactive face generation\n",
    "\n",
    "You can modify the `CHECKPOINT_PATH` at the top to compare different training runs (distributed vs local) or different epochs!"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
