{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Distributed GAN training demo - Generate celebrity faces\n",
        "\n",
        "This notebook demonstrates how to use our pre-trained DCGAN model to generate realistic celebrity faces.\n",
        "\n",
        "**What you'll do:**\n",
        "- Load a pre-trained DCGAN model from Hugging Face\n",
        "- Generate random celebrity faces\n",
        "- Experiment with different random seeds\n",
        "- Compare with real CelebA images (optional)\n",
        "\n",
        "**No training required!** The model is already trained and ready to use."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. Import required libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "from pathlib import Path\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import yaml\n",
        "from huggingface_hub import hf_hub_download\n",
        "\n",
        "# Add src to path\n",
        "sys.path.insert(0, '../src')\n",
        "\n",
        "from models.dcgan import Generator\n",
        "\n",
        "# Set plotting style\n",
        "plt.style.use('default')\n",
        "%matplotlib inline\n",
        "\n",
        "print(f\"PyTorch version: {torch.__version__}\")\n",
        "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Load configuration\n",
        "\n",
        "Load settings from config.yaml - this makes the notebook automatically use your project's Hugging Face repository."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load configuration from config.yaml\n",
        "config_path = Path('../config.yaml')\n",
        "\n",
        "if not config_path.exists():\n",
        "    raise FileNotFoundError(\n",
        "        'config.yaml not found! Make sure you are running this notebook from the notebooks/ directory.'\n",
        "    )\n",
        "\n",
        "with open(config_path) as f:\n",
        "    config = yaml.safe_load(f)\n",
        "\n",
        "# Model configuration\n",
        "LATENT_DIM = config['model']['latent_dim']\n",
        "IMAGE_SIZE = config['data']['image_size']\n",
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Hugging Face model settings from config\n",
        "hf_config = config.get('huggingface', {})\n",
        "HF_REPO_ID = hf_config.get('repo_id', '')\n",
        "MODEL_FILENAME = 'checkpoint_latest.pth'\n",
        "\n",
        "print(f'Configuration loaded from config.yaml')\n",
        "print(f'  Device: {DEVICE}')\n",
        "print(f'  Image size: {IMAGE_SIZE}x{IMAGE_SIZE}')\n",
        "print(f'  Latent dimension: {LATENT_DIM}')\n",
        "print(f'  Hugging Face repo: {HF_REPO_ID}')\n",
        "\n",
        "if not HF_REPO_ID:\n",
        "    print('\\nWarning: No Hugging Face repo configured in config.yaml')\n",
        "    print('   Update the huggingface section in config.yaml with your repo details.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Download pre-trained model\n",
        "\n",
        "Download the trained generator model from Hugging Face Hub. This only needs to happen once - the model will be cached locally.\n",
        "\n",
        "The model is automatically downloaded from the repository specified in your config.yaml file."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check if HF repo is configured\n",
        "if not HF_REPO_ID:\n",
        "    print('No Hugging Face repository configured!')\n",
        "    print('\\nTo use this notebook, you need to:')\n",
        "    print('  1. Train a model (or have access to a trained model)')\n",
        "    print('  2. Update config.yaml with your Hugging Face repo details:')\n",
        "    print('     huggingface:')\n",
        "    print('       enabled: true')\n",
        "    print('       repo_id: your-username/your-repo')\n",
        "    print('  3. Make sure the model has been uploaded to Hugging Face')\n",
        "    raise ValueError('Hugging Face repo_id not configured in config.yaml')\n",
        "\n",
        "# Create models directory if it does not exist\n",
        "models_dir = Path('../models')\n",
        "models_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Path where model will be saved\n",
        "model_path = models_dir / MODEL_FILENAME\n",
        "\n",
        "# Download from Hugging Face or use local copy\n",
        "try:\n",
        "    if not model_path.exists():\n",
        "        print(f'Downloading model from Hugging Face: {HF_REPO_ID}...')\n",
        "        downloaded_path = hf_hub_download(\n",
        "            repo_id=HF_REPO_ID,\n",
        "            filename=MODEL_FILENAME,\n",
        "            cache_dir=models_dir\n",
        "        )\n",
        "        print(f'Model downloaded to: {downloaded_path}')\n",
        "        model_path = Path(downloaded_path)\n",
        "    else:\n",
        "        print(f'Using cached model: {model_path}')\n",
        "    \n",
        "    # Initialize generator\n",
        "    generator = Generator(latent_dim=LATENT_DIM).to(DEVICE)\n",
        "    \n",
        "    # Load weights\n",
        "    checkpoint = torch.load(model_path, map_location=DEVICE)\n",
        "    \n",
        "    # Handle different checkpoint formats\n",
        "    if isinstance(checkpoint, dict) and 'generator_state_dict' in checkpoint:\n",
        "        generator.load_state_dict(checkpoint['generator_state_dict'])\n",
        "    else:\n",
        "        generator.load_state_dict(checkpoint)\n",
        "    \n",
        "    generator.eval()\n",
        "    \n",
        "    # Print model info\n",
        "    num_params = sum(p.numel() for p in generator.parameters())\n",
        "    print(f'\\nGenerator loaded successfully!')\n",
        "    print(f'  Parameters: {num_params:,}')\n",
        "    print(f'  Input: {LATENT_DIM}D random noise')\n",
        "    print(f'  Output: {IMAGE_SIZE}x{IMAGE_SIZE} RGB images')\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f'\\nError loading model: {e}')\n",
        "    print(f'\\nTroubleshooting:')\n",
        "    print(f'  Make sure your model has been uploaded to: {HF_REPO_ID}')\n",
        "    print(f'  Verify the file is named: {MODEL_FILENAME}')\n",
        "    print(f'  Check your Hugging Face token is valid')\n",
        "    print(f'  Visit: https://huggingface.co/{HF_REPO_ID}')\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Generate celebrity faces\n",
        "\n",
        "Generate random celebrity faces from the trained model. Each time you run this cell, you'll get different faces!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate faces\n",
        "num_samples = 16\n",
        "\n",
        "with torch.no_grad():\n",
        "    # Sample random noise from normal distribution\n",
        "    noise = torch.randn(num_samples, LATENT_DIM, 1, 1, device=DEVICE)\n",
        "    \n",
        "    # Generate images\n",
        "    generated_images = generator(noise).cpu()\n",
        "\n",
        "# Display in a grid\n",
        "fig, axes = plt.subplots(4, 4, figsize=(12, 12))\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    # Convert from [-1, 1] to [0, 1] for display\n",
        "    img = (generated_images[i].numpy() + 1) / 2\n",
        "    img = np.transpose(img, (1, 2, 0))\n",
        "    img = np.clip(img, 0, 1)\n",
        "    \n",
        "    ax.imshow(img)\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.suptitle('Generated celebrity faces', fontsize=16, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f'Generated {num_samples} unique faces from random noise!')\n",
        "print(f'\\nTip: Run this cell multiple times to see different faces each time.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Reproducible generation with seeds\n",
        "\n",
        "Use a random seed to generate the same faces consistently. Useful for debugging or creating consistent examples."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Set seed for reproducibility\n",
        "SEED = 42  # Change this to get different (but reproducible) faces\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed(SEED)\n",
        "\n",
        "num_samples = 8\n",
        "\n",
        "with torch.no_grad():\n",
        "    noise = torch.randn(num_samples, LATENT_DIM, 1, 1, device=DEVICE)\n",
        "    generated_images = generator(noise).cpu()\n",
        "\n",
        "# Display\n",
        "fig, axes = plt.subplots(2, 4, figsize=(14, 7))\n",
        "\n",
        "for i, ax in enumerate(axes.flat):\n",
        "    img = (generated_images[i].numpy() + 1) / 2\n",
        "    img = np.transpose(img, (1, 2, 0))\n",
        "    img = np.clip(img, 0, 1)\n",
        "    \n",
        "    ax.imshow(img)\n",
        "    ax.set_title(f'Seed {SEED}, #{i+1}', fontsize=10)\n",
        "    ax.axis('off')\n",
        "\n",
        "plt.suptitle(f'Reproducible faces (seed={SEED})', fontsize=14, fontweight='bold')\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(f'Generated with seed {SEED}')\n",
        "print(f'\\nThese faces will be the same every time you run with this seed.')\n",
        "print(f'Change SEED to get different reproducible faces.')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Compare with real images (optional)\n",
        "\n",
        "If you have the CelebA dataset locally, compare generated faces with real ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "try:\n",
        "    from data.dataset import CelebADataset\n",
        "    \n",
        "    # Load dataset path from config\n",
        "    DATASET_PATH = config['data']['dataset_path']\n",
        "    dataset = CelebADataset(DATASET_PATH, image_size=IMAGE_SIZE)\n",
        "    \n",
        "    print(f'Dataset loaded: {len(dataset):,} images')\n",
        "    \n",
        "    # Sample random real images\n",
        "    num_samples = 8\n",
        "    np.random.seed(42)\n",
        "    indices = np.random.choice(len(dataset), num_samples, replace=False)\n",
        "    \n",
        "    # Create comparison figure\n",
        "    fig, axes = plt.subplots(2, 8, figsize=(16, 4))\n",
        "    \n",
        "    # Top row: Real images\n",
        "    for i, idx in enumerate(indices):\n",
        "        img, _ = dataset[idx]\n",
        "        img = (img.numpy() + 1) / 2\n",
        "        img = np.transpose(img, (1, 2, 0))\n",
        "        img = np.clip(img, 0, 1)\n",
        "        \n",
        "        axes[0, i].imshow(img)\n",
        "        axes[0, i].axis('off')\n",
        "        if i == 0:\n",
        "            axes[0, i].set_title('Real', fontsize=10, loc='left')\n",
        "    \n",
        "    # Bottom row: Generated images\n",
        "    with torch.no_grad():\n",
        "        noise = torch.randn(num_samples, LATENT_DIM, 1, 1, device=DEVICE)\n",
        "        generated_images = generator(noise).cpu()\n",
        "    \n",
        "    for i in range(num_samples):\n",
        "        img = (generated_images[i].numpy() + 1) / 2\n",
        "        img = np.transpose(img, (1, 2, 0))\n",
        "        img = np.clip(img, 0, 1)\n",
        "        \n",
        "        axes[1, i].imshow(img)\n",
        "        axes[1, i].axis('off')\n",
        "        if i == 0:\n",
        "            axes[1, i].set_title('Generated', fontsize=10, loc='left')\n",
        "    \n",
        "    plt.suptitle('Real vs Generated comparison', fontsize=14, fontweight='bold')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f'Dataset not available: {e}')\n",
        "    print(f'This is optional - the model works without the dataset!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Try it yourself!\n",
        "\n",
        "Experiment with generating faces. Try modifying the code above or use the cell below for experimentation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Your experiments here!\n",
        "# Ideas:\n",
        "# - Generate a single high-quality image\n",
        "# - Try different numbers of samples\n",
        "# - Save your favorite generated faces\n",
        "# - Generate faces with specific seeds\n",
        "\n",
        "# Example: Generate and save a single face\n",
        "with torch.no_grad():\n",
        "    noise = torch.randn(1, LATENT_DIM, 1, 1, device=DEVICE)\n",
        "    face = generator(noise).cpu()\n",
        "\n",
        "# Display\n",
        "plt.figure(figsize=(5, 5))\n",
        "img = (face[0].numpy() + 1) / 2\n",
        "img = np.transpose(img, (1, 2, 0))\n",
        "img = np.clip(img, 0, 1)\n",
        "plt.imshow(img)\n",
        "plt.axis('off')\n",
        "plt.title('Generated face', fontsize=14)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# To save: plt.imsave('my_generated_face.png', img)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## Summary\n",
        "\n",
        "You have learned how to:\n",
        "- Load a pre-trained DCGAN model from Hugging Face\n",
        "- Generate random celebrity faces from noise\n",
        "- Use seeds for reproducible generation\n",
        "- Compare generated vs real images\n",
        "\n",
        "### Next steps\n",
        "\n",
        "Want to train your own model? Check out:\n",
        "- `src/train_local.py` - Train on a single GPU\n",
        "- `src/main.py` - Distributed training across multiple workers\n",
        "\n",
        "### How the model works\n",
        "\n",
        "The DCGAN (Deep Convolutional GAN) consists of:\n",
        "- **Generator**: Transforms 100D random noise into 64x64 RGB images\n",
        "- **Discriminator**: Distinguishes real from generated images\n",
        "\n",
        "Through adversarial training, the generator learns to create realistic faces that fool the discriminator!\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
